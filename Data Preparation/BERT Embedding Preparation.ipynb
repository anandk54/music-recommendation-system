{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1GItLbnBw4bq"
      },
      "outputs": [],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## **BERT** **Embeddings** **Preparation**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2HjsKFwRvmgq"
      },
      "outputs": [],
      "source": [
        "!pip install tensorflow_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5_JdQNvFvuAm"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import pickle\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Loading Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q1N2cbMivw4T"
      },
      "outputs": [],
      "source": [
        "data1 = pickle.load(open('/content/drive/MyDrive/Minor Project/30music.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNveXZJjv3aE"
      },
      "outputs": [],
      "source": [
        "data1['Frequency'] = data1.groupby('UserId')['UserId'].transform('count')\n",
        "data1.sort_values('Frequency', inplace=True, ascending=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wbx_IBJGv4ue"
      },
      "outputs": [],
      "source": [
        "data = data1[:6000]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mom5am4Jv9tO"
      },
      "outputs": [],
      "source": [
        "words = list(data['ItemId'].unique())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGEblF2oKBgm"
      },
      "outputs": [],
      "source": [
        "words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1uZOMHKAwA-8"
      },
      "outputs": [],
      "source": [
        "bert_preprocess_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3'\n",
        "bert_encoder_url = 'https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4'\n",
        "\n",
        "bert_preprocess = hub.KerasLayer(bert_preprocess_url)\n",
        "bert_model = hub.KerasLayer(bert_encoder_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jGHGiSlwwECS"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def get_similarity(sentences):\n",
        "    preprocessed_text = bert_preprocess(sentences)\n",
        "    result = bert_model(preprocessed_text)\n",
        "    return cosine_similarity([result['pooled_output'][0]], [result['pooled_output'][1]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7eFX0GG1wHdc"
      },
      "outputs": [],
      "source": [
        "def get_embedding(sentence, embedding_length):\n",
        "    preprocessed_text = bert_preprocess(sentence)\n",
        "    result = bert_model(preprocessed_text)\n",
        "    return result['pooled_output'][0][0:embedding_length]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "piYWjeVvzdga"
      },
      "outputs": [],
      "source": [
        "def prepare_dataset(window, top_n, words, data):\n",
        "   \n",
        "    df = data.groupby(by=['SessionId'])\n",
        "    for s, d in df:\n",
        "        d = d.sort_values(by=['Time'])\n",
        "    \n",
        "    basket = []\n",
        "    next_song = []\n",
        "    for s, d in df:\n",
        "        words = list(d['ItemId'])\n",
        "        i = 1\n",
        "        j = top_n\n",
        "        m = window+top_n\n",
        "        if m > len(d):\n",
        "            m = len(d)\n",
        "        while j < m:\n",
        "            basket.append(words[0:i])\n",
        "            next_song.append(words[i:j])\n",
        "            i += 1\n",
        "            j += 1\n",
        "        for i in range(len(d)-window-top_n-1):\n",
        "            basket.append(words[i:i+window])\n",
        "            next_song.append(words[i+window:i+window+top_n])\n",
        "\n",
        "    return (basket, next_song)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzjdqJt8zebj"
      },
      "outputs": [],
      "source": [
        "def get_dataset(window, top_n, words, data, m, emb_length):\n",
        "    \n",
        "    (basket, next_song) = prepare_dataset(window, top_n, words, data)\n",
        "            \n",
        "    song_basket = np.zeros((len(basket), window, emb_length), dtype=np.int32)\n",
        "    recommended_song = np.zeros((len(next_song), top_n), dtype=np.int32)\n",
        "    for i, each_words in enumerate(basket):\n",
        "       for j, each_word in enumerate(each_words):\n",
        "          emb = m[each_word]\n",
        "          for k in range(emb_length):\n",
        "            song_basket[i, j, k] = emb[k]\n",
        "    \n",
        "    for i, top_songs in enumerate(next_song):\n",
        "        for j, song  in enumerate(top_songs):\n",
        "            recommended_song[i, j] = song\n",
        "    \n",
        "    return (song_basket, recommended_song)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preparing Embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iNfykGabHlVZ"
      },
      "outputs": [],
      "source": [
        "m = {}\n",
        "for w in words:\n",
        "  m[w] = get_embedding([str(w)], 50)\n",
        "\n",
        "pickle.dump(m, open(f'/content/drive/MyDrive/Minor Project/bert_embs_50.pkl'))\n",
        "\n",
        "(song_basket, recommended_song) = get_dataset(5, 1, words, data, m, 50)\n",
        "\n",
        "pickle.dump(song_basket, open(f'/content/drive/MyDrive/Minor Project/song_basket_bert_5_1_50.pkl', 'wb'))\n",
        "pickle.dump(recommended_song, open(f'/content/drive/MyDrive/Minor Project/recommended_song_bert_5_1_50.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-PxWj82Nzsgo"
      },
      "outputs": [],
      "source": [
        "m = pickle.load(open('/content/drive/MyDrive/Minor Project/bert_embs.pkl', 'rb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uOldqGb7zol4"
      },
      "outputs": [],
      "source": [
        "(song_basket, recommended_song) = get_dataset(5, 1, words, data, m, 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "StIKFQtbz8-A"
      },
      "outputs": [],
      "source": [
        "pickle.dump(song_basket, open('/content/drive/MyDrive/Minor Project/song_basket_bert_5_1_50.pkl', 'wb'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3UiREk070V31"
      },
      "outputs": [],
      "source": [
        "pickle.dump(recommended_song, open('/content/drive/MyDrive/Minor Project/recommended_song_bert_5_1_50.pkl', 'wb'))"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
